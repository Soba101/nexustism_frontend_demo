Plan: Frontend PRD for ITSM Nexus - Standalone Document
A comprehensive, self-contained Product Requirements Document for the ITSM Nexus frontend application that can be understood without accessing source code. The PRD will explain the two-stage ML pipeline architecture, user workflows, technical stack decisions, visualization strategies, authentication model, feedback mechanisms, and phased delivery plan in business-friendly language with sufficient technical depth for implementation teams.
Steps
Executive Summary & Product Vision — Define the business problem (IT support engineers waste 30-45 minutes searching for solutions to recurring incidents), product solution (AI-powered similarity search and root cause detection using 10,633 historical ServiceNow incidents), target outcomes (50% reduction in resolution time, 80% search accuracy based on user validation, enterprise-wide adoption within 3 months), competitive differentiation (two-stage ML approach combining fast vector search with deep causal analysis vs traditional keyword-only search), and strategic alignment (modernize ITSM operations, reduce operational costs, improve customer satisfaction through faster incident resolution).
User Personas & Use Cases — Document four primary personas: (1) L1/L2 Support Engineer (Sarah, 2 years experience, handles 20-30 tickets/day, needs quick answers to common problems, frustrated by outdated knowledge base, prefers visual interfaces over documentation); (2) L3 Technical Analyst (Marcus, 5 years experience, investigates complex multi-system failures, needs to trace root causes across related incidents, requires detailed metadata and causal reasoning); (3) IT Service Manager (Jennifer, 10 years experience, monitors team performance and trends, needs dashboards showing resolution metrics and category distributions, requires exportable reports for stakeholder meetings); (4) ML Engineer (Dev, maintains the similarity model, collects user feedback to improve accuracy, needs structured export of validation data for retraining cycles). Include detailed user stories for each persona with acceptance criteria.
System Architecture Overview — Explain the complete system architecture in non-technical terms: backend API service running on port 8001 providing search and analysis endpoints, PostgreSQL database with vector extension storing 10,633 incidents and their 768-dimensional mathematical representations, Supabase platform providing authentication and data security, Next.js web application running the user interface with server-side rendering for fast initial loads, and Docker containerization for consistent deployment across environments. Include data flow diagrams showing user query → similarity search → causal analysis → results display → feedback collection → model improvement cycle.
Two-Stage ML Pipeline Explanation — Describe the ML architecture for business stakeholders: Stage 1 - Fast Similarity Search uses a fine-tuned MPNet model that converts incident descriptions into 768-number vectors representing semantic meaning, enabling mathematical comparison of ticket similarity within 100 milliseconds, finding top 10-50 candidates from the full database using approximate nearest neighbor search optimized with specialized indexes; Stage 2 - Causal Classification takes the similarity candidates and uses a cross-encoder model to determine if one incident caused another by analyzing their descriptions, categories, timelines, and relationships, producing a causality confidence score from 0-100%. Explain the hybrid RRF (Reciprocal Rank Fusion) search combining keyword matching with semantic similarity for better recall.
Feature Specifications - Search Interface — Detail the primary search experience: centered search bar with typeahead suggestions after 3 characters, filter sidebar with collapsible sections for Category (checkboxes for Hardware, Software, Network, Database, etc.), Priority (Critical/High/Medium/Low multi-select), State (Open/In Progress/Resolved/Closed), and Date Range (calendar picker for opened_at and resolved_at fields). Results display as paginated table with columns: Ticket Number (clickable), Short Description (truncated to 100 chars with ellipsis), Category (colored badge), Priority (color-coded High=red, Medium=orange, Low=green), Similarity Score (percentage with progress bar visualization), and Actions (View Details button, Feedback thumbs). Include advanced features: query expansion toggle showing synonyms added (e.g., "VPN" expands to "virtual private network, remote access"), reranking toggle that re-scores top results with slower but more accurate model, sort options (by similarity, by date, by priority), and export button generating CSV of current results.
Feature Specifications - Incident Detail Panel — Describe the detail view opened when user clicks a search result: slide-over panel from right side (desktop) or full-screen modal (mobile) displaying complete incident information in organized tabs - Overview Tab shows ticket number, current state with status badge, priority indicator, category breadcrumb, opened date/time, resolved date/time (if applicable), assigned group, short description as heading, full description in expandable text area (collapsed at 200 chars), and service/service offering metadata; Related Incidents Tab displays similar tickets found by the system with similarity percentages, causal relationships if detected (showing "This incident may have caused:" and "This incident may be caused by:" sections with confidence scores), and visual timeline if multiple related incidents exist; Timeline Tab shows incident lifecycle with state transitions, assignment changes, and resolution notes; Audit Log Tab (admin only) displays all database changes with timestamps and user IDs. Include feedback widget at bottom with thumbs up/down buttons, star rating for causal predictions, and optional comment text area.
Feature Specifications - Causal Analysis Visualization — Specify the root cause analysis interface: dedicated page accessed via "Analyze Root Cause" button on incident detail panel, displays interactive directed graph with incidents as nodes and causal relationships as arrows, root incident highlighted in blue at center, caused incidents shown in gray, high-confidence causal links (>70% probability) shown as red animated arrows with thickness proportional to confidence score, medium-confidence (50-70%) as orange dashed lines, low-confidence (<50%) as thin gray lines. Node design: rounded rectangle showing ticket number, truncated description (40 chars), priority badge, and date; clicking node opens detail panel; hovering shows tooltip with full description and metadata. Graph controls: zoom in/out buttons, fit-to-view reset, layout algorithm selector (hierarchical top-down for clear cause→effect flow, force-directed for clustering related incidents, radial for single-root analysis), pan by dragging canvas, export graph as PNG or SVG image. Validation interface: sidebar listing all causal relationships with 5-star rating widget ("How confident are you this is a true cause?"), confidence slider (0-100%), evidence text area, and submit button.
Feature Specifications - Analytics Dashboard — Define the manager-focused analytics view: page header with date range selector (Last 7 Days, Last 30 Days, Last Quarter, Custom Range), four metric cards showing Total Incidents (count with trend arrow vs previous period), Average Resolution Time (hours with percentage change), Search Usage (total searches with adoption rate percentage), and Top Category (most frequent with percentage of total). Charts section: Incident Trend line chart showing daily opened/resolved counts over time with dual Y-axis, hoverable data points with exact counts and dates; Category Distribution horizontal bar chart showing incident counts by category sorted by frequency, with percentage labels; Priority Breakdown donut chart showing proportion of Critical/High/Medium/Low incidents with legend; Resolution Time Trends area chart showing average hours to resolution over time by priority level. Export button for all charts generating PDF report with embedded visualizations and summary statistics table. Refresh button for manual data update (auto-refreshes every 5 minutes).
Authentication & Security Model — Explain the security architecture: Supabase Auth handles all user management with email/password signup/login flows including email verification, password reset via secure token links, and session management with automatic token refresh. OAuth integration for enterprise SSO supporting Google Workspace and GitHub for quick login without password. Role-based access control with three levels: Anonymous users can view public documentation only, Authenticated users (verified email) can search incidents, view details, provide feedback, and access personal dashboard, Admin users additionally access feedback export, manual sync triggers, system health metrics, and audit logs. Row-level security policies ensure users only access data they're authorized for - all incident data is read-only for end users, only the ServiceNow pipeline can write new incidents, feedback data is visible only to the submitting user and admins. Session timeout after 30 minutes of inactivity with warning at 25 minutes, all authentication tokens stored in httpOnly cookies to prevent JavaScript access and XSS attacks.
Feedback & Model Improvement Loop — Detail the continuous improvement system: Similarity Feedback collected via thumbs up/down buttons on every search result, clicking thumbs down opens comment dialog asking "What's wrong with this result?" with free-text field (optional), all feedback logged with query text, result ticket number, similarity score, timestamp, and user ID for later analysis. Causal Validation collected via 5-star rating interface on relationship graphs, stars represent confidence (1=definitely wrong, 3=unsure, 5=definitely correct), optional confidence percentage slider for precision, evidence text field for analysts to explain their reasoning, all validation logged with incident pair IDs, predicted causal score, user rating, and timestamp. Implicit Signals automatically tracked: which search results users click (position in ranking indicates relevance), time spent viewing incident details (longer = more useful), whether user resolves ticket after viewing similar incident (successful resolution), navigation paths through related incidents (breadcrumb trail). Data export for retraining: admin panel includes "Export Feedback" button generating JSON file matching the model's training data format with fields for incident text pairs, similarity labels (1.0 for thumbs up, 0.0 for thumbs down), confidence scores (explicit feedback = 1.0, implicit clicks = 0.3), and metadata (original score, user comment, timestamp) ready for curriculum learning retraining process.
Export & Reporting Capabilities (MVP) — Specify all export features: Search Results Export via CSV download button above results table, includes columns for all visible fields plus hidden metadata (opened_at, resolved_at, assignment_group, service), filename format "itsm_search_results_YYYYMMDD_HHMMSS.csv", maximum 1000 rows per export (prompt for filtered export if more). Graph Export via "Download Graph" button on causal analysis page generating PNG image (1920x1080 resolution for presentations) or SVG vector graphic (scalable for documentation), includes legend explaining node colors and edge styles, filename includes root incident number "causal_graph_INC001234_YYYYMMDD.png". Analytics Reports via "Generate Report" button creating PDF document with embedded charts as images, summary statistics table, date range and filter parameters, company logo header, and footer with generation timestamp, suitable for stakeholder presentations. Feedback Export (admin only) generates JSON file with all user feedback from selected date range in model training format, includes metadata for tracking feedback quality, used quarterly for model retraining cycles.
Internationalization & Accessibility — Define inclusive design requirements: support for three languages in MVP (English as default, Spanish, French) with locale switcher in user profile settings, all UI labels and messages translated using next-intl library with professional translations (no machine translation), date/time formatting respects user locale (MM/DD/YYYY for US, DD/MM/YYYY for Europe), number formatting uses locale-appropriate thousands separators and decimal points. Accessibility compliance with WCAG 2.1 Level AA: keyboard navigation for all features (Tab to move between controls, Enter to activate, Escape to close dialogs, arrow keys for graph traversal), focus indicators visible on all interactive elements with 3px blue outline, ARIA labels on all buttons and inputs describing their purpose ("Search incidents by description", "Rate this causal relationship 5 stars"), screen reader support with meaningful announcements (search results count "Showing 27 results for laptop freezing", graph navigation "Incident INC001234, caused by INC001199, press Enter for details"), color-blind safe palettes avoiding red-green only distinctions (use shapes plus colors: High priority = red triangle, Medium = orange circle, Low = green square), minimum 4.5:1 contrast ratio for all text verified via automated testing, semantic HTML with proper heading hierarchy (h1 for page title, h2 for sections, h3 for subsections), alternative text for all visualizations describing their content ("Line chart showing 234 incidents opened last week, peak of 45 on Tuesday").
Performance & Optimization Requirements — Set measurable performance targets: initial page load under 3 seconds on 3G mobile network (measured via Lighthouse), search results displayed within 500 milliseconds of backend response (client-side rendering time), graph visualization loads in under 2 seconds for 100 nodes, Time to Interactive under 5 seconds on desktop. Optimization strategies: code splitting loads only necessary components per page (graph visualization library loaded only on causal analysis page, chart library only on analytics dashboard), lazy loading for images and below-fold content, virtual scrolling for result lists exceeding 100 items (renders only visible rows), API response caching for 1 minute to avoid duplicate requests during page navigation, service worker caches recently viewed incidents for offline access to last 50 searches, progressive enhancement ensures basic search works even if JavaScript fails (server-side rendering provides initial HTML), image optimization with automatic WebP conversion and responsive sizes, bundle size target under 300KB for initial JavaScript payload.
Development & Deployment Roadmap — Plan phased delivery: MVP Phase (6 weeks, Target: March 2026) delivers search dashboard with hybrid search, incident detail panel, email/password authentication, similarity feedback thumbs up/down, CSV export, responsive design for desktop/tablet/mobile, deployed to Vercel staging environment, acceptance testing with 10 pilot users from IT support team, success metrics: 80% search relevance rating, <5 critical bugs, 100% accessibility test pass rate. Phase 2 (4 weeks, Target: April 2026) adds causal graph visualization with React Flow, causal validation star ratings, analytics dashboard with 4 charts, OAuth for Google/GitHub, PDF graph export, real-time incident updates via WebSocket showing toast notifications, Command palette for power users (Cmd+K shortcut), deployed to production with feature flags for gradual rollout to 25% of users, success metrics: 70% of analysts use graph visualization weekly, average 15 causal validations per day. Phase 3 (3 weeks, Target: May 2026) adds advanced filters (date range, assignment group, custom fields), saved search presets, Spanish/French translations, admin feedback export, scheduled weekly email reports, embedding space visualization for ML explainability, full production rollout to 100% of users, success metrics: 50% reduction in average resolution time for known issues, 90% daily active user rate. Phase 4 (4 weeks, Target: June 2026) includes mobile optimization with touch gestures, offline support with service worker, advanced analytics cohort analysis, batch operations for bulk resolving, webhook integrations for external ITSM tools, performance optimization achieving <2s load time, final polish and stability improvements.
Further Considerations
WebSocket Real-time Requirements — Should Phase 2 real-time features include presence indicators showing other users viewing the same incident (with user avatars and "3 people viewing this ticket" badge), collaborative annotations where multiple analysts can mark causal relationships simultaneously with conflict resolution, or just simple notifications for new incidents matching current search filters and status updates on followed tickets? This affects backend architecture complexity and database schema for presence tracking.
ServiceNow Sync Status Transparency — The admin panel should show ServiceNow sync information - should this include detailed sync logs with record-level success/failure status (showing which specific tickets failed to sync and why), manual conflict resolution interface when ServiceNow data differs from database (with side-by-side comparison and "Keep ServiceNow" or "Keep Database" buttons), or just high-level metrics like last sync timestamp, total records synced, and error count with alert if sync fails?
Graph Complexity Management — For incidents with many relationships (>50 related tickets), should the interface implement graph pagination (initially show 10 highest-confidence causal links with "Load More" button), cluster grouping (combine similar incidents into expandable groups reducing visual clutter), or depth limiting (show only 2 levels from root incident with toggle to expand full tree)? This affects both UX and rendering performance.
Feedback Data Quality Validation — Before exporting feedback for model retraining, should the system implement quality checks like minimum rating threshold (require at least 3-star certainty for causal validation to be included), spam detection (flag users submitting >20 ratings in 1 minute), consensus validation (only use feedback where multiple users agree), or manual admin review workflow (admin approves/rejects feedback before export)? This affects data quality but adds administrative overhead.
Mobile-First vs Desktop-First Design — Given complex visualizations, should the design prioritize desktop experience (full-featured graph visualization with simplified mobile view) or mobile-first with progressive enhancement (design for touch interactions first, add mouse/keyboard shortcuts for desktop)? This affects which Phase 1 features are feasible given 85% of IT support staff use desktop workstations but 40% do initial triage on mobile devices.
Search Query Complexity — Should MVP support only simple text queries ("laptop freezing") or include advanced syntax like Boolean operators ("category:hardware AND priority:high"), field-specific search ('description:"database connection"'), wildcards ("INC0012*"), and date ranges ("opened:2025-01-01..2025-01-31")? Advanced syntax requires backend changes and user training but provides power-user capabilities that reduce need for filter clicking.

additionals:
Is the level of technical detail appropriate for your stakeholders (product managers, executives, implementation teams)?
Should the document include user journey wireframes or keep descriptions text-only?
Are there other personas beyond the four defined (support engineer, analyst, manager, ML engineer) that need consideration?
Should success metrics be more aggressive (e.g., 70% resolution time reduction instead of 50%)?

ensure naming is genric for future ticket implementation
ensure all buttons are working as expected.
this should function as a admin dashboard